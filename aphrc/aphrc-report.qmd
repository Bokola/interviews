---
title: "Predicting New COVID-19 Cases in the US: A Comparison of a Compartmental Model (SIR) and XGBoost Machine Learning Model"
author: "Basil Okola"
date: today
date-format: "MMMM DD, YYYY"
abstract: |
  **Background**: Figuring out the number of new COVID-19 cases was key in aligning interventions to hotspots. This included ensuring there were enough beds for admissions, key protection gear like face masks, oxygen supply and intensive care unit space. A lot of mechanistic models were build borrowing from the traditional SIR model. Additionally, researchers explored machine learning techniques to predict the course of the infections.
  
  **Methods**: In this report, we compare the performance of a SIR model to an XGBOOST prediction model in predicting new cases in each of the American states, 3 years after the pandemic.
  
  **Results**: The XGBOOST ML approach demonstrated robust goodness-of-fit, effectively capturing the non-linear peak dynamics across varying geographic replicates.
format: 
  pdf:
    keep-tex: true
    number-sections: true
    geometry: margin=1in
    header-includes:
      - \usepackage{sectsty}
      - \usepackage{xcolor}
      - \usepackage{fancyhdr}
      - \definecolor{wdlblue}{HTML}{012D4A}
      - \definecolor{wdlteal}{HTML}{00A7B5}
      - \sectionfont{\color{wdlblue}\uppercase}
      - \subsectionfont{\color{wdlblue}}
      - \usepackage{etoolbox}
      - \makeatletter
      - \patchcmd{\@sect}{\fi#7}{\fi\color{wdlteal}\hrule height 1.5pt \kern 3pt\color{black}#7}{}{}
      - \makeatother
      - \pagestyle{fancy}
editor_options: 
  chunk_output_type: console
execute:
  echo: false
  warning: false
bibliography: reference.bib
csl: https://raw.githubusercontent.com/citation-style-language/styles/master/dependent/the-lancet-infectious-diseases.csl
---


# Introduction

We chose to use data on COVID-19 cases assembled by a team from [The London School of Health & Tropical Medicine](https://vac-lshtm.shinyapps.io/ncov_tracker/#) who built a global COVID-19 tracker shiny app. This was purely due to convenience and the short turn around time for the assessment as there was an already ongoing personal project that modularized parts of the said app into a golem framework and so it was easier adding a prediction modelling capabilities rather than starting a new project. The [COVID19Dash](https://github.com/Bokola/COVID19Dash) app can be installed from github and run seamlessly. For  predictions look at the `Prediction Model` tab.

# Methods

## Data

We used `cv_states` data that is part of the datasets in the `COVID19Dash` package. It compiles daily COVID-19 cases in each of the states in the US. It also comes with limited spatial support (longitudes & latitudes). We chose `new_cases` as the outcome variable and generated rolling means for 7, 14, and 30 days as predictors in addition to the frequency of each state in the data to avoid having to encode the categorical variable.

## Models

We fitted a SIR model - a compartmental mechanistic framework that simulates the spread of infectious diseases by transitioning a population through susceptible, infectious, and recovered states using differential equations. It relies on the interaction between the transmission rate $\beta$ and the recovery rate $\gamma$ to determine the velocity and peak of an epidemic curve [@ross1916application].

### SIR framework

The mechanistic sir model assumes a fixed population $N$ where individuals transition between susceptible ($S$), infectious ($I$), and recovered ($R$) compartments. the dynamics are governed by the following system of ordinary differential equations, which were implemented using the `desolve` package in our workflow:

$$\begin{aligned}
\frac{dS}{dt} &= -\beta \frac{S I}{N} \\
\frac{dI}{dt} &= \beta \frac{S I}{N} - \gamma I \\
\frac{dR}{dt} &= \gamma I
\end{aligned}$$

where $\beta$ represents the effective transmission rate and $\gamma$ denotes the removal or recovery rate. individuals are assumed to move from the susceptible to the infectious compartment at a rate proportional to the product of $S$ and $I$.

A critical threshold in this modeling framework is the basic reproduction number ($R_0$), which defines the average number of secondary infections produced by a single infected individual in a completely susceptible population. in our analysis, we calculated $R_0$ using the optimized parameters from each state:

$$R_0 = \frac{\beta}{\gamma}$$

An epidemic persists only when $R_0 > 1$. our model fitting used an optimization routine to minimize the residuals between the predicted $I(t)$ compartment and the observed case ratios across the 50 american states.

### XGBOOST model

We also fitted an XGBOOST model to predict the new cases. XGBoost, or Extreme Gradient Boosting, is an ensemble decision‐tree algorithm, like
random forest regressions, but able to model more complex interactions due to its ability to boost individual trees and does not rely on a single tree. It uses a scalable tree‐boosting system to optimize predictions [@chen2016xgboost].

## Missing data

We did not encounter missing data. However, depending on the objective of the research, there are a number of pathways available. In a purely ML prediction setting, researchers apply simple methods like mean/median for numeric variables or mode for categorical variables. In a purely inferential task, multiple imputations are employed under missing at random (MAR) assumption and a sensitivity analysis done to verify that the imputation method is not driving model decisions.

## Accounting for spatial and tempororal structure

We did not work with a hierarchical spatial and temporal variation. However, one approach is through Hierarchical Bayesian models. In R this can be accomplished through R-INLA [@moraga2019geospatial]. This involves decomposing observed variance into structured and unstructured random effects across multiple levels, using neighboring data to inform estimates in sparse regions.


```{r setup, include=FALSE}
pacman::p_load(
  "tidyverse", "kableExtra", "xgboost", "deSolve"
)
if(!require(devtools)) install.packages("devtools")

# run once
# devtools::install_github("bokola/COVID19Dash")

library(COVID19Dash)


wdl_blue   <- "#012d4a"
wdl_teal   <- "#00a7b5"
wdl_gray   <- "#58595b"
wdl_light  <- "#f4f7f9"
msf_orange <- "#FF5F00"
msf_red <- "#EB001B"

# dummy data for demonstration
# data_sample <- data.frame(
#   date = seq(as.Date("2025-01-01"), by = "day", length.out = 100),
#   new_cases = cumsum(runif(100, 5, 20)),
#   population = 1000000,
#   latitude = 1.29,
#   longitude = 36.82
# )


```


```{r}
# contains core functions for sir and ml modeling

run_modelling_engine <- function(df) {
  # setup colors as constants for use in plots
  cols <- list(
    blue = "#012d4a", teal = "#00a7b5", gray = "#58595b",
    light = "#f4f7f9", orange = "#FF5F00", red = "#EB001B"
  )
  
  # data prep
  df_clean <- df %>%
    mutate(date = as.Date(date),
           time_index = as.numeric(date - min(date)),
           case_ratio = new_cases / population) %>%
    arrange(date)
  
  # xgboost modelling
  feats <- c("latitude", "longitude", "time_index") 
  x <- as.matrix(df_clean[, feats])
  y <- df_clean$new_cases
  
  model_xgb <- xgboost::xgb.train(
    params = list(objective = "reg:squarederror", learning_rate = 0.1),
    data = xgboost::xgb.DMatrix(x, label = y), 
    nrounds = 25, verbose = 0
  )
  df_clean$preds_xgb <- predict(model_xgb, x)
  
  # sir modelling
  y0 <- c(S = 0.999, I = max(df_clean$case_ratio[1], 1e-5), R = 0)
  fit <- optim(
    par = c(beta = 0.25, gamma = 0.1),
    fn = function(p) {
      out <- try(deSolve::ode(y = y0, times = df_clean$time_index, func = function(t,v,p) {
        list(c(-p[1]*v[1]*v[2], p[1]*v[1]*v[2] - p[2]*v[2], p[2]*v[2]))
      }, parms = p), silent = TRUE)
      if (inherits(out, "try-error")) return(1e12)
      sum((out[,3] - df_clean$case_ratio)^2, na.rm = TRUE)
    },
    method = "L-BFGS-B", lower = c(0.01, 0.01), upper = c(2.0, 1.0)
  )
  
  sir_res <- as.data.frame(deSolve::ode(y = y0, times = df_clean$time_index, 
                                        func = function(t,v,p) list(c(-p[1]*v[1]*v[2], p[1]*v[1]*v[2] - p[2]*v[2], p[2]*v[2])), 
                                        parms = fit$par))
  df_clean$preds_sir <- sir_res[,3] * df_clean$population[1]
  
  return(list(data = df_clean, params = fit$par, colors = cols))
}

# run analysis
data("cv_states")
results <- run_modelling_engine(cv_states)
df <- results$data
cols <- results$colors
```

# Results

## Model comparisons

The XGBOOST performed better than the simple SIR model in predicting new cases.

```{r}
ggplot(df[df$state == "Alabama",], aes(x = date)) +
  geom_point(aes(y = new_cases), color = cols$gray, alpha = 0.4) +
  geom_line(aes(y = preds_xgb, color = "XGBoost (ML)"), size = 1) +
  geom_line(aes(y = preds_sir, color = "SIR (Mechanistic)"), size = 1, linetype = "dashed") +
  scale_color_manual(values = c("XGBoost (ML)" = cols$blue, "SIR (Mechanistic)" = cols$orange)) +
  theme_minimal() +
  labs(title = "Daily Case Projections",
       subtitle = "Comparison of ML and SIR outputs",
       y = "New Cases", x = "Date", color = "Model Type") +
  theme(
    plot.title = element_text(color = cols$blue, face = "bold"),
    legend.position = "bottom"
  )
```

# Discussions

We have build two models and compared their performance using visual plots and other metrics logged to the shiny app. We did not however undertake a simulation due to time constraints. We consulted AI on figuring out bugs from XGBOOST which we found to be a challenge running in R environment. 

# Reproducibility

Install the [COVID19Dash](https://github.com/Bokola/COVID19Dash) using `devtools::install_github("bokola/COVID19Dash")` command. You can then run the app interactively by calling `run_app()`. To reproduce the contents of this document, ensure the other packages called in `setup` chunk are installed.

# Reference

